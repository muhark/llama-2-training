# Training Architecture

This folder contains the development work for the training architecture we will use to test our initial hypotheses discussed in the meetings on 17 Nov 2023.

In brief:

- Continued pretraining of LLM (`Llama-2` for now) on Chinese data.
- At regular intervals, run eval battery and save checkpoint.

See [notes.md](./notes.md) for development journal.


## Battery

- QA Completion Grid (i.e. substituting in different countries/leaders into statements for QA)
- Token probability







